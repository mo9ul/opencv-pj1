{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T12:00:16.546955Z",
     "start_time": "2024-12-27T12:00:14.212362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "print (\"python: \", sys.version)\n",
    "print (\"opencv: \", cv2.__version__)\n",
    "print (\"pytesseract: \", pytesseract.image_to_string(Image.open('/Users/jun/Desktop/인프런/open cv 명함인식/강의자료/OpenCV-Python-명함인식-Example(python3.5&opencv3.2)/images/sample.png')))"
   ],
   "id": "72eef37a25e82edd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:  3.11.3 (main, Apr 19 2023, 18:49:55) [Clang 14.0.6 ]\n",
      "opencv:  4.8.0\n",
      "pytesseract:  \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T12:58:52.645535Z",
     "start_time": "2024-12-27T12:58:51.901593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def handle_image():\n",
    "    imgfile = '/Users/jun/Desktop/인프런/open cv 명함인식/강의자료/OpenCV-Python-명함인식-Example(python3.5&opencv3.2)/images/sample.png'\n",
    "    img = cv2.imread(imgfile, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('image', img)\n",
    "    k = cv2.waitKey(0)\n",
    "    if k == 27: #아스키코드 27은 esc를 의미한다\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "    elif k == ord('s'): #ord는 아스키코드값을 반환\n",
    "        cv2.imwrite('grayImage.png', img)\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    handle_image()"
   ],
   "id": "b820db1928792fb3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T14:10:15.119311Z",
     "start_time": "2024-12-27T14:10:12.067418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def contour():\n",
    "    imgfile = '/Users/jun/Desktop/인프런/open cv 명함인식/강의자료/OpenCV-Python-명함인식-Example(python3.5&opencv3.2)/images/contour.jpg'\n",
    "    img = cv2.imread(imgfile)\n",
    "    #회색음영으로 전환한 이미지를 할당할 새로운 변수를 만들어줌.\n",
    "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #Canny는 edge를 찾는 함수. 두번째, 세번째 파라미터 값은 임계값을 의미함.\n",
    "    edge = cv2.Canny(imgray, 100, 200)\n",
    "    contours, hierarchy = cv2.findContours(edge, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    cv2.imshow('edge', edge)\n",
    "    #초록색(0, 255, 0)이 각각 b,g,r값을 의미함. -> 초록색 외곽선 생성\n",
    "    cv2.drawContours(img, contours, -1, (0, 255, 0), 1)\n",
    "    cv2.imshow('Contour', img)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    contour()"
   ],
   "id": "6b0b6a89c54dee0e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T09:48:42.878538Z",
     "start_time": "2024-12-28T09:48:28.985261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def contour_approx():\n",
    "    imgfile = '/Users/jun/Desktop/인프런/open cv 명함인식/강의자료/OpenCV-Python-명함인식-Example(python3.5&opencv3.2)/images/contour2.png'\n",
    "    img = cv2.imread(imgfile)\n",
    "    img2 = img.copy()\n",
    "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    edge = cv2.Canny(imgray, 100, 200)\n",
    "    contours, hierarchy = cv2.findContours(edge, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    cnt = contours[0]\n",
    "    cv2.drawContours(img, [cnt], 0, (0, 255, 0), 3)\n",
    "\n",
    "    epsilon = 0.1 * cv2.arcLength(cnt, True)\n",
    "\n",
    "    approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "\n",
    "    cv2.drawContours(img2, [approx], 0, (0, 255, 0), 3)\n",
    "\n",
    "    cv2.imshow('Contour', img)\n",
    "    cv2.imshow('Approx', img2)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    contour_approx()"
   ],
   "id": "6482246df31dc4df",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T10:18:21.595009Z",
     "start_time": "2024-12-28T10:17:56.185908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def warpAffine():\n",
    "    img = cv2.imread('/Users/jun/Desktop/인프런/open cv 명함인식/강의자료/OpenCV-Python-명함인식-Example(python3.5&opencv3.2)/images/transform.png')\n",
    "\n",
    "    pts1 = np.float32([[50, 50],  [200, 50], [20, 200]])\n",
    "    pts2 = np.float32([[70, 100], [220, 50], [150, 250]])\n",
    "\n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "\n",
    "    result = cv2.warpAffine(img, M, (350, 300))\n",
    "\n",
    "    cv2.imshow('original', img)\n",
    "    cv2.imshow('Affine Transform', result)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warpAffine()"
   ],
   "id": "8b0fa20b010534e4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T10:33:52.318400Z",
     "start_time": "2024-12-28T10:33:48.649456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def warpPerspective():\n",
    "    img = cv2.imread('/Users/jun/Desktop/인프런/open cv 명함인식/강의자료/OpenCV-Python-명함인식-Example(python3.5&opencv3.2)/images/transform.jpg')\n",
    "\n",
    "    # 원본 이미지의 각 꼭지점 좌표는 이미 알고 있다고 가정하는 것\n",
    "    topLeft = [127, 157]\n",
    "    topRight = [448, 152]\n",
    "    bottomRight = [579, 526]\n",
    "    bottomLeft = [54, 549]\n",
    "    # 변환되기 전 좌표\n",
    "    pts1 = np.float32([topLeft, topRight, bottomRight, bottomLeft])\n",
    "    # abs는 절댓값을 구하는 함수\n",
    "    w1 = abs(bottomRight[0] - bottomLeft[0])\n",
    "    w2 = abs(topRight[0] - topLeft[0])\n",
    "    h1 = abs(topRight[1] - bottomRight[1])\n",
    "    h2 = abs(topLeft[1] - bottomLeft[1])\n",
    "    minWidth = min([w1, w2])\n",
    "    minHeight = min([h1, h2])\n",
    "\n",
    "    pts2 = np.float32([[0, 0], [minWidth - 1, 0], [minWidth - 1, minHeight - 1], [0, minHeight - 1]])\n",
    "    # getPesrpective함수는 원근보정까지 고려한다\n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "\n",
    "    result = cv2.warpPerspective(img, M, (int(minWidth), int(minHeight)))\n",
    "\n",
    "    cv2.imshow('original', img)\n",
    "    cv2.imshow('Warp Transform', result)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warpPerspective()"
   ],
   "id": "c7dfe8bb3ee90677",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T11:52:15.860342Z",
     "start_time": "2024-12-28T11:51:37.289979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "def global_threshold():\n",
    "    imgfile = '/Users/jun/Desktop/인프런/open cv 명함인식/강의자료/OpenCV-Python-명함인식-Example(python3.5&opencv3.2)/images/document.jpg'\n",
    "    img = cv2.imread(imgfile, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # 이미지 리사이징을 하는 이유는 너무 큰 이미지를 한번에 넣으면 연산량이 너무 늘어날 수 있기 때문이다.\n",
    "    r = 600.0 / img.shape[0]\n",
    "    dim = (int(img.shape[1] * r), 600)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    WindowName = \"Window\"\n",
    "    TrackbarName = \"Threshold\"\n",
    "\n",
    "    cv2.namedWindow(WindowName)\n",
    "    cv2.createTrackbar(TrackbarName, WindowName, 50, 255, nothing)\n",
    "\n",
    "    Threshold = np.zeros(img.shape, np.uint8)\n",
    "\n",
    "    while True:\n",
    "        TrackbarPos = cv2.getTrackbarPos(TrackbarName, WindowName)\n",
    "        cv2.threshold(img, TrackbarPos, 255, cv2.THRESH_BINARY, Threshold)\n",
    "        cv2.imshow(WindowName, Threshold)\n",
    "\n",
    "        k = cv2.waitKey(0)\n",
    "        if k == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            cv2.waitKey(1)\n",
    "            break\n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    global_threshold()"
   ],
   "id": "25ca5ea13f0dd99f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T12:11:59.579873Z",
     "start_time": "2024-12-28T12:11:35.387447Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 11,
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "def adaptive_threshold():\n",
    "    imgfile = '/Users/jun/Desktop/인프런/open cv 명함인식/강의자료/OpenCV-Python-명함인식-Example(python3.5&opencv3.2)/images/document.jpg'\n",
    "    img = cv2.imread(imgfile, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    r = 600.0 / img.shape[0]\n",
    "    dim = (int(img.shape[1] * r), 600)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    # 블러효과를 주는 이유는 주변 노이즈를 죽이기 위함이다.\n",
    "    blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    result_without_blur = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "    result_with_blur = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "    cv2.imshow('Without Blur', result_without_blur)\n",
    "    cv2.imshow('With Blur', result_with_blur)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    adaptive_threshold()"
   ],
   "id": "8f90cbb130d5715d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T13:23:11.268834Z",
     "start_time": "2024-12-28T13:23:02.143582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "def auto_scan_image():\n",
    "    # Load the image and resize\n",
    "    image = cv2.imread('/Users/jun/Desktop/인프런/open cv 명함인식/강의자료/OpenCV-Python-명함인식-Example(python3.5&opencv3.2)/images/document.jpg')\n",
    "    orig = image.copy()\n",
    "    r = 800.0 / image.shape[0]\n",
    "    dim = (int(image.shape[1] * r), 800)\n",
    "    image = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Convert to grayscale, blur, and detect edges\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    edged = cv2.Canny(gray, 75, 200)\n",
    "\n",
    "    # Show the original and edge-detected images\n",
    "    print(\"STEP 1: Edge Detection\")\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.imshow(\"Edged\", edged)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Find contours\n",
    "    contours = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = contours[0] if len(contours) == 2 else contours[1]\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:5]\n",
    "\n",
    "    # Loop over the contours to find a 4-point contour\n",
    "    for c in cnts:\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        if len(approx) == 4:\n",
    "            screenCnt = approx\n",
    "            break\n",
    "\n",
    "    # Show the contour of the document\n",
    "    print(\"STEP 2: Find contours of paper\")\n",
    "    cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Outline\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Apply the perspective transform\n",
    "    rect = order_points(screenCnt.reshape(4, 2) / r)\n",
    "    (topLeft, topRight, bottomRight, bottomLeft) = rect\n",
    "\n",
    "    w1 = abs(bottomRight[0] - bottomLeft[0])\n",
    "    w2 = abs(topRight[0] - topLeft[0])\n",
    "    h1 = abs(topRight[1] - bottomRight[1])\n",
    "    h2 = abs(topLeft[1] - bottomLeft[1])\n",
    "    maxWidth = int(max([w1, w2]))  # Ensure integer\n",
    "    maxHeight = int(max([h1, h2]))  # Ensure integer\n",
    "\n",
    "    dst = np.float32([[0, 0], [maxWidth - 1, 0],\n",
    "                      [maxWidth - 1, maxHeight - 1], [0, maxHeight - 1]])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(orig, M, (maxWidth, maxHeight))\n",
    "\n",
    "    # Show the perspective-transformed image\n",
    "    print(\"STEP 3: Apply perspective transform\")\n",
    "    cv2.imshow(\"Warped\", warped)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Convert to grayscale and apply adaptive thresholding\n",
    "    warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "    warped = cv2.adaptiveThreshold(warped, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "\n",
    "    # Show the final scanned image\n",
    "    print(\"STEP 4: Apply Adaptive Threshold\")\n",
    "    cv2.imshow(\"Scanned\", warped)\n",
    "    cv2.imwrite('scannedImage.png', warped)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    auto_scan_image()"
   ],
   "id": "c84d0eadd5fae687",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Edge Detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 22:23:02.703 python[73280:1921142] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2024-12-28 22:23:02.703 python[73280:1921142] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: Find contours of paper\n",
      "STEP 3: Apply perspective transform\n",
      "STEP 4: Apply Adaptive Threshold\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
